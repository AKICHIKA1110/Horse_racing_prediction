{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ea6d609-a9a1-438a-8074-78428507459b",
   "metadata": {},
   "source": [
    "# 閲覧サイトとURL\n",
    "**netkeiba.com**:競走馬のデータ, 競走結果, 血統情報, トレーニング成績\n",
    "\n",
    "https://www.netkeiba.com/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7ed9925-79b0-429a-8635-274be5e09409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSVファイルにデータを書き込みました。\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import time\n",
    "\n",
    "# データを格納するためのリストを初期化\n",
    "horse_data_list = []\n",
    "\n",
    "# page=1からpage=626までの各ページを順にスクレイピング\n",
    "for page in range(1, 5):\n",
    "    # スクレイピングするウェブページのURL\n",
    "    url = f'https://db.netkeiba.com//?pid=horse_list&word=&x=27&y=6&act=1&page={page}'\n",
    "    # requestsを使ってURLの内容を取得\n",
    "    response = requests.get(url)\n",
    "    # ステータスコードが200（正常にコンテンツが取得できた）場合のみ処理を続行\n",
    "    if response.status_code == 200:\n",
    "        # BeautifulSoupを使ってHTMLを解析\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        # 各馬の情報が含まれる<td>要素を取得\n",
    "        horse_cells = soup.find_all('td', class_='bml txt_l')\n",
    "\n",
    "        # 各<td>要素から情報を抽出してリストに追加\n",
    "        for cell in horse_cells:\n",
    "            horse_name = cell.find('a').text.strip()\n",
    "    \n",
    "            sex = cell.find_next_sibling(class_='txt_c').text.strip()\n",
    "    \n",
    "            birth_year_element = cell.find_next_sibling(class_='txt_c').find_next_sibling(class_='txt_c').find('a')\n",
    "            birth_year = birth_year_element.text.strip() if birth_year_element else ''\n",
    "    \n",
    "            trainer_element = cell.find_next_sibling(class_='txt_l').find('a')\n",
    "            trainer = trainer_element.text.strip() if trainer_element else ''\n",
    "    \n",
    "            sire_element = cell.find_next_sibling(class_='txt_l').find_next_sibling(class_='txt_l').find('a')\n",
    "            sire = sire_element.text.strip() if sire_element else ''\n",
    "    \n",
    "            mare_element = cell.find_next_sibling(class_='txt_l').find_next_sibling(class_='txt_l').find_next_sibling(class_='txt_l').find('a')\n",
    "            mare = mare_element.text.strip() if mare_element else ''\n",
    "    \n",
    "            damsire_element = cell.find_next_sibling(class_='txt_l').find_next_sibling(class_='txt_l').find_next_sibling(class_='txt_l').find_next_sibling(class_='txt_l').find('a')\n",
    "            damsire = damsire_element.text.strip() if damsire_element else ''\n",
    "    \n",
    "            owner_element = cell.find_next_sibling(class_='txt_l').find_next_sibling(class_='txt_l').find_next_sibling(class_='txt_l').find_next_sibling(class_='txt_l').find('a')\n",
    "            owner = owner_element.text.strip() if owner_element else ''\n",
    "    \n",
    "            breeder_element = cell.find_next_sibling(class_='txt_l').find_next_sibling(class_='txt_l').find_next_sibling(class_='txt_l').find_next_sibling(class_='txt_l').find_next_sibling(class_='txt_l').find('a')\n",
    "            breeder = breeder_element.text.strip() if breeder_element else ''\n",
    "    \n",
    "            prize_money = cell.find_next_sibling(class_='txt_r').text.strip()\n",
    "\n",
    "            horse_data_list.append([horse_name, sex, birth_year, trainer, sire, mare, damsire, owner, breeder, prize_money])\n",
    "\n",
    "        # 馬の情報がリストに格納されました\n",
    "        for horse_data in horse_data_list:\n",
    "            \n",
    "\n",
    "        # 少し待機してから次のページへ（ウェブサイトへの負荷軽減のため）\n",
    "            time.sleep(1)\n",
    "\n",
    "# データをCSVファイルに書き込む\n",
    "with open('horse_data.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    \n",
    "    # CSVのヘッダーを書き込む\n",
    "    writer.writerow(['馬名', '性別', '生年', '厩舎', '父', '母', '母父', '馬主', '生産者', '総賞金(万円)'])\n",
    "    \n",
    "    # 馬の情報をCSVに書き込む\n",
    "    for horse_data in horse_data_list:\n",
    "        writer.writerow(horse_data)\n",
    "\n",
    "print('CSVファイルにデータを書き込みました。')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c990bf98-46da-4ac5-b754-f2ae219219c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSVファイルにゴールタイムを書き込みました。\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import time\n",
    "\n",
    "# データを格納するためのリストを初期化\n",
    "horse_data_list = []\n",
    "\n",
    "# page=1からpage=4までの各ページを順にスクレイピング\n",
    "for page in range(1, 2):\n",
    "    url = f'https://db.netkeiba.com//?pid=horse_list&word=&x=27&y=6&act=1&page={page}'\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        horse_cells = soup.find_all('td', class_='bml txt_l')\n",
    "\n",
    "        for cell in horse_cells:\n",
    "            horse_name = cell.find('a').text.strip()\n",
    "            horse_url = 'https://db.netkeiba.com' + cell.find('a')['href']  # 馬の詳細ページのURL\n",
    "            \n",
    "            # 馬の詳細ページにアクセスしてゴールタイムを取得\n",
    "            horse_response = requests.get(horse_url)\n",
    "            horse_soup = BeautifulSoup(horse_response.content, 'html.parser')\n",
    "            goal_time_tag = horse_soup.find('td', string='ゴールタイム')  \n",
    "            goal_time = goal_time_tag.find_next('td').text.strip() if goal_time_tag else 'データなし'\n",
    "            \n",
    "            # 馬のデータをリストに追加\n",
    "            horse_data_list.append([horse_name, goal_time])\n",
    "            time.sleep(1)\n",
    "\n",
    "# データをCSVファイルに書き込む\n",
    "with open('horse_goal_times.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['馬名', 'ゴールタイム'])\n",
    "    for horse_data in horse_data_list:\n",
    "        writer.writerow(horse_data)\n",
    "\n",
    "print('CSVファイルにゴールタイムを書き込みました。')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19aa9748-e90f-48c1-820c-6d3dccb8f837",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import time\n",
    "\n",
    "def scrape_race_data(url):\n",
    "    # レスポンスの取得\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        return \"Error: Unable to fetch the page.\"\n",
    "\n",
    "    # データを解析\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # データを格納するリストを初期化\n",
    "    race_data_list = []\n",
    "\n",
    "    # レース情報の取得\n",
    "    race_info = soup.find('div', class_='RaceData01').get_text(strip=True)\n",
    "    distance = race_info.split('/')[0].split('m')[0]  # 距離の抽出\n",
    "\n",
    "    # 各馬の情報を取得\n",
    "    horse_rows = soup.find_all('tr', class_='HorseList')\n",
    "    for row in horse_rows:\n",
    "        cells = row.find_all('td')\n",
    "        if cells:\n",
    "            horse_name = cells[3].find('a').get_text(strip=True)  # 馬名\n",
    "            horse_weight = cells[14].get_text(strip=True).split('(')[0]  # 馬体重\n",
    "            goal_time = cells[11].get_text(strip=True)  # ゴールタイム\n",
    "            race_data_list.append([horse_name, horse_weight, goal_time, distance])\n",
    "\n",
    "    return race_data_list\n",
    "\n",
    "# メインの実行部\n",
    "if __name__ == '__main__':\n",
    "    # スクレイピングするレースのURL\n",
    "    race_url = 'https://www.example.com/race/result/url'\n",
    "    race_results = scrape_race_data(race_url)\n",
    "\n",
    "    # CSVに書き込む\n",
    "    with open('race_data.csv', 'w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['馬名', '馬体重', 'ゴールタイム', '距離'])\n",
    "        writer.writerows(race_results)\n",
    "\n",
    "    print('データがCSVファイルに保存されました。')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
